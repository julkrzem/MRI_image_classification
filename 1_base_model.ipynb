{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saved dataset was loaded, and a custom preprocessing function (preprocess.py) was applied to simplify the data loading process. The function was designed to take the raw data, convert it into a Dataset object, and then split it into separate DataLoader instances for train, test, and validation. The function also enables to apply additional transformations, but for this basic test it was used without any additional processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(\"dataset.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(\"weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampled data was split into test, train validation and prepared with DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader,testloader,valloader = preprocess(dataset, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_example = images[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next step the network architecture was copied from the PyTorch tutorial on training a classifier (https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-a-classifier) to maintain a relatively simple architecture and use it as a baseline.\n",
    "\n",
    "The layer dimensions were adjusted by testing the input and output shapes step by step while gradually adding layers from the example network. While itâ€™s possible to calculate the dimensions of the convolutional layers manually, I find this approach simpler and less prone to errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=2)\n",
    "pool = nn.MaxPool2d(2,2)\n",
    "conv_2 = nn.Conv2d(6, 16, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 30, 30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool(conv_2(pool(conv_1(tensor_example)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14400])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(pool(conv_2(pool(conv_1(tensor_example))))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*30*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=2)\n",
    "pool = nn.MaxPool2d(2, 2)\n",
    "conv2 = nn.Conv2d(6, 16, 4)\n",
    "fc1 = nn.Linear(16*30*30, 256)\n",
    "fc3 = nn.Linear(256, 64)\n",
    "fc4 = nn.Linear(64, 4)\n",
    "\n",
    "x = tensor_example\n",
    "x = pool(F.relu(conv1(x)))\n",
    "x = pool(F.relu(conv2(x)))\n",
    "x = torch.flatten(x)\n",
    "x.shape\n",
    "x = F.relu(fc1(x))\n",
    "x = F.relu(fc3(x))\n",
    "x = fc4(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 4)\n",
    "        self.fc1 = nn.Linear(16*30*30, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the layer dimensions were calculated, a new model class was created and used for training. The optimizer and loss function from the tutorial were adopted. \n",
    "\n",
    "A custom training loop was implemented with an added early stopping mechanism to break training when the loss on the test dataset no longer improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=14400, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(os.getenv(\"DEVICE\"))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 1.3491527549922466, Test loss: 1.2519595623016357\n",
      "Epoch: 1, Train loss: 1.11840146407485, Test loss: 1.025646448135376\n",
      "Epoch: 2, Train loss: 0.9153427947312593, Test loss: 0.8508386015892029\n",
      "Epoch: 3, Train loss: 0.7443269863724709, Test loss: 0.7712833881378174\n",
      "Epoch: 4, Train loss: 0.6505684684962034, Test loss: 0.6088495254516602\n",
      "Epoch: 5, Train loss: 0.5756431622430682, Test loss: 0.5529963970184326\n",
      "Epoch: 6, Train loss: 0.5227594068273902, Test loss: 0.5518519878387451\n",
      "Epoch: 7, Train loss: 0.496339812874794, Test loss: 0.5747254490852356\n",
      "Epoch: 8, Train loss: 0.48608595319092274, Test loss: 0.4834904372692108\n",
      "Epoch: 9, Train loss: 0.4240690218284726, Test loss: 0.4513201415538788\n",
      "Epoch: 10, Train loss: 0.3842144990339875, Test loss: 0.43257296085357666\n",
      "Epoch: 11, Train loss: 0.34341618325561285, Test loss: 0.4053606688976288\n",
      "Epoch: 12, Train loss: 0.33919435925781727, Test loss: 0.42551738023757935\n",
      "Epoch: 13, Train loss: 0.2704439852386713, Test loss: 0.3617243468761444\n",
      "Epoch: 14, Train loss: 0.27539269626140594, Test loss: 0.34711629152297974\n"
     ]
    }
   ],
   "source": [
    "best_result = np.inf\n",
    "test_loss_array = []\n",
    "n_epochs = 15\n",
    "patience = 3\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in trainloader:\n",
    "\n",
    "        X_batch = X_batch.to(device,dtype=torch.float32)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(X_batch)\n",
    "\n",
    "        loss = criterion(outputs.to(device), y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() \n",
    "\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():  \n",
    "            \n",
    "            for X_batch, y_batch in testloader:\n",
    "\n",
    "                X_batch = X_batch.to(device,dtype=torch.float32)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                outputs = net(X_batch)\n",
    "                t_loss = criterion(outputs.to(device), y_batch)\n",
    "\n",
    "                test_loss+=t_loss\n",
    "\n",
    "    loss = total_loss / (len(trainloader))\n",
    "    loss_test = test_loss / (len(testloader))\n",
    "\n",
    "    test_loss_array.append(loss_test)\n",
    "\n",
    "    if loss_test < best_result:\n",
    "        torch.save(net.state_dict(), \"./base_net.pth\")\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Train loss: {loss}, Test loss: {loss_test}\")\n",
    "\n",
    "    if len(test_loss_array)>patience+1:\n",
    "        if not (any(x > test_loss_array[-1] for x in test_loss_array[len(test_loss_array)-patience-1:-1])):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was loaded from saved path and used for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"base_net.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "f1_scr = []\n",
    "precision = []\n",
    "recall=[]\n",
    "\n",
    "pred = []\n",
    "actual = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for X_batch, y_batch in valloader:\n",
    "        outputs_pred = net(X_batch.to(device))\n",
    "\n",
    "        _, topi = outputs_pred.topk(1)\n",
    "\n",
    "        topi=topi.cpu()\n",
    "\n",
    "        acc = accuracy_score(y_batch,topi.squeeze(-1))\n",
    "        f1 = f1_score(y_batch,topi.squeeze(-1), average=\"macro\")\n",
    "        pr = precision_score(y_batch,topi.squeeze(-1), average=\"macro\")\n",
    "        rec = recall_score(y_batch,topi.squeeze(-1),average=\"macro\")\n",
    "\n",
    "        pred += topi.squeeze(-1).tolist()\n",
    "        actual += y_batch.tolist()\n",
    "\n",
    "        accuracy.append(float(acc))\n",
    "        f1_scr.append(float(f1))\n",
    "        precision.append(float(pr))\n",
    "        recall.append(float(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final result is quite good especially since:\n",
    "- simple architecture was used with minor changes \n",
    "- the dataset is quite small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8628615702479339\n",
      "0.8556276517616439\n",
      "0.8607067042189462\n",
      "0.8606469326833457\n"
     ]
    }
   ],
   "source": [
    "print(statistics.mean(accuracy))\n",
    "print(statistics.mean(f1_scr))\n",
    "print(statistics.mean(precision))\n",
    "print(statistics.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\"pred\":pred, \"actual\":actual})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"correct\"] = results_df[\"pred\"] ==results_df[\"actual\"] \n",
    "results_df[\"total\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results_df[[\"actual\", \"correct\", \"total\"]].groupby(\"actual\").agg(sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"acc\"] = result[\"correct\"]/ result[\"total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>correct</th>\n",
       "      <th>total</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "      <td>336</td>\n",
       "      <td>0.967262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>332</td>\n",
       "      <td>0.885542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>215</td>\n",
       "      <td>313</td>\n",
       "      <td>0.686901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>333</td>\n",
       "      <td>365</td>\n",
       "      <td>0.912329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  correct  total       acc\n",
       "0       0      325    336  0.967262\n",
       "1       1      294    332  0.885542\n",
       "2       2      215    313  0.686901\n",
       "3       3      333    365  0.912329"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The group most difficult to identify was 2 - meningioma, often mistaken for glioma or even a negative sample. On the other hand with glioma cases ot was sometimes mistaken by a different type of tumor but never mistaken for a negative sample - which mean the pathology was always spotted in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred\n",
       "0    325\n",
       "2      6\n",
       "3      3\n",
       "1      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df[\"actual\"] == 0][\"pred\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred\n",
       "1    294\n",
       "2     35\n",
       "3      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df[\"actual\"] == 1][\"pred\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred\n",
       "2    215\n",
       "1     48\n",
       "0     33\n",
       "3     17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df[\"actual\"] == 2][\"pred\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred\n",
       "3    333\n",
       "2     20\n",
       "1      9\n",
       "0      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df[\"actual\"] == 3][\"pred\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
